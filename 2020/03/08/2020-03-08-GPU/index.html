<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico">
  <link rel="mask-icon" href="/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"acewzj.github.io","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="这篇文章主要记述了GPU并行编程CUDA的一些笔记。">
<meta property="og:type" content="article">
<meta property="og:title" content="GPU并行编程--CUDA模型学习">
<meta property="og:url" content="http://acewzj.github.io/2020/03/08/2020-03-08-GPU/index.html">
<meta property="og:site_name" content="acewzj">
<meta property="og:description" content="这篇文章主要记述了GPU并行编程CUDA的一些笔记。">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2020/03/30/HtDAjOmXqVnLKgb.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/Lp1crIB4K5EmHQX.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/gJCWhvV6HkwqTd2.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/lY8G7mgMEnroPa2.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/zXL9xRYIdmP6SEO.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/gMdYEFTuqoCByi1.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/RbHi3vYFqhWt7yK.png">
<meta property="og:image" content="https://i.loli.net/2020/03/30/pEVzKnYhoGvtjOe.png">
<meta property="og:image" content="http://acewzj.github.io/2020/03/08/2020-03-08-GPU/1584244854962.png">
<meta property="og:image" content="https://i.loli.net/2020/03/29/jewqLO3yNzpb8Fm.png">
<meta property="og:image" content="http://acewzj.github.io/2020/03/08/2020-03-08-GPU/1584367353177.png">
<meta property="article:published_time" content="2020-03-08T02:16:18.000Z">
<meta property="article:modified_time" content="2020-04-02T10:25:33.356Z">
<meta property="article:author" content="acewzj">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="GPU">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/03/30/HtDAjOmXqVnLKgb.png">

<link rel="canonical" href="http://acewzj.github.io/2020/03/08/2020-03-08-GPU/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>GPU并行编程--CUDA模型学习 | acewzj</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">acewzj</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">王忠杰</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acewzj.github.io/2020/03/08/2020-03-08-GPU/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="acewzj">
      <meta itemprop="description" content="acewzj">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="acewzj">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          GPU并行编程--CUDA模型学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-08 10:16:18" itemprop="dateCreated datePublished" datetime="2020-03-08T10:16:18+08:00">2020-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-02 18:25:33" itemprop="dateModified" datetime="2020-04-02T18:25:33+08:00">2020-04-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/C/" itemprop="url" rel="index"><span itemprop="name">C++</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>这篇文章主要记述了GPU并行编程CUDA的一些笔记。</p>
<a id="more"></a>






<p><img src="https://i.loli.net/2020/03/30/HtDAjOmXqVnLKgb.png" alt="1583476702566"></p>
<p>32是考虑流水线【取指–执行—-】</p>
<p><img src="https://i.loli.net/2020/03/30/Lp1crIB4K5EmHQX.png" alt="1583478205636"></p>
<p><img src="https://i.loli.net/2020/03/30/gJCWhvV6HkwqTd2.png" alt="1583480186631"></p>
<p>均匀分布比起高斯分布具有更高的信息熵（更混乱，因为均匀分布说明物体很多且分布均匀，而高斯分布集中在峰值那块，更整齐一些）</p>
<p><img src="https://i.loli.net/2020/03/30/lY8G7mgMEnroPa2.png" alt="1583995920661"></p>
<p><img src="https://i.loli.net/2020/03/30/zXL9xRYIdmP6SEO.png" alt="1583996284858"></p>
<p>第二个式子是保证正负号的，也就是保证分类正确（因为求w最小求出两个值）</p>
<p><img src="https://i.loli.net/2020/03/30/gMdYEFTuqoCByi1.png" alt="1583998459306"></p>
<p>可以使用 <code>nvidia-smi</code> (<em>Systems Management Interface</em>) 命令行命令查询有关此 GPU 的信息。</p>
<p><img src="https://i.loli.net/2020/03/30/RbHi3vYFqhWt7yK.png" alt="1584235758864"></p>
<p>可以通过以下方式轻松解决这种情况：</p>
<ul>
<li>编写执行配置，使其创建的线程数<strong>超过</strong>执行分配工作所需的线程数。</li>
<li>将值作为参数传递到核函数 (<code>N</code>) 中，以表示要处理的数据集总大小或完成工作所需的总线程数。</li>
<li>计算网格内的线程索引后（使用 <code>tid+bid*bdim</code>），请检查该索引是否超过 <code>N</code>，并且只在不超过的情况下执行与核函数相关的工作。</li>
</ul>
<p>以下是编写执行配置的惯用方法示例，适用于 <code>N</code> 和线程块中的线程数已知，但无法保证网格中的线程数和 <code>N</code> 之间完全匹配的情况。如此一来，便可确保网格中至少始终拥有 <code>N</code> 所需的线程数，且超出的线程数至多仅可相当于 1 个线程块的线程数量：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Assume `N` is known</span></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">100000</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Assume we have a desire to set `threads_per_block` exactly to `256`</span></span><br><span class="line"><span class="keyword">size_t</span> threads_per_block = <span class="number">256</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Ensure there are at least `N` threads in the grid, but only 1 block's worth extra</span></span><br><span class="line"><span class="keyword">size_t</span> number_of_blocks = (N + threads_per_block - <span class="number">1</span>) / threads_per_block;</span><br><span class="line"></span><br><span class="line">some_kernel&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;(N);</span><br></pre></td></tr></table></figure>

<p>由于上述执行配置致使网格中的线程数超过 <code>N</code>，因此需要注意 <code>some_kernel</code> 定义中的内容，以确保 <code>some_kernel</code> 在由其中一个 \”extra\” 线程执行时不会尝试访问超出范围的数据元素：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="title">some_kernel</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (idx &lt; N) <span class="comment">// Check to make sure `idx` maps to some value within `N`</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// Only do work if it does</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/03/30/pEVzKnYhoGvtjOe.png" alt="1584163725409"></p>
<hr>
<h2 id="Allocating-Memory-to-be-accessed-on-the-GPU-and-the-CPU"><a href="#Allocating-Memory-to-be-accessed-on-the-GPU-and-the-CPU" class="headerlink" title="Allocating Memory to be accessed on the GPU and the CPU"></a>Allocating Memory to be accessed on the GPU and the CPU</h2><p>CUDA 的最新版本（版本 6 和更高版本）已能轻松分配可用于 CPU 主机和任意数量 GPU 设备的内存。尽管现今有许多适用于内存管理并可支持加速应用程序中最优性能的 <a href="http://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations" target="_blank" rel="noopener">中高级技术</a>，但我们现在要介绍的基础 CUDA 内存管理技术不但能够支持远超 CPU 应用程序的卓越性能，而且几乎不会产生任何开发人员成本。</p>
<p>如要分配和释放内存，并获取可在主机和设备代码中引用的指针，请使用 <code>cudaMallocManaged</code> 和 <code>cudaFree</code> 取代对 <code>malloc</code> 和 <code>free</code> 的调用，如下例所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CPU-only</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="keyword">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *a;</span><br><span class="line">a = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(size);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use `a` in CPU-only program.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">free</span>(a);</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Accelerated</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line"><span class="keyword">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> *a;</span><br><span class="line"><span class="comment">// Note the address of `a` is passed as first argument.</span></span><br><span class="line">cudaMallocManaged(&amp;a, size);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Use `a` on the CPU and/or on any GPU in the accelerated system.</span></span><br><span class="line"></span><br><span class="line">cudaFree(a);</span><br></pre></td></tr></table></figure>

<h2 id="Data-Sets-Larger-then-the-Grid"><a href="#Data-Sets-Larger-then-the-Grid" class="headerlink" title="Data Sets Larger then the Grid"></a>Data Sets Larger then the Grid</h2><p>或出于选择，为了要创建具有超高性能的执行配置，或出于需要，一个网格中的线程数量可能会小于数据集的大小。请思考一下包含 1000 个元素的数组和包含 250 个线程的网格（此处使用极小的规模以便于说明）。此网格中的每个线程将需使用 4 次。如要实现此操作，一种常用方法便是在核函数中使用<strong>网格跨度循环</strong>。</p>
<p>在网格跨度循环中，每个线程将在网格内使用 <code>tid+bid*bdim</code> 计算自身唯一的索引，并对数组内该索引的元素执行相应运算，然后将网格中的线程数添加到索引并重复此操作，直至超出数组范围。例如，对于包含 500 个元素的数组和包含 250 个线程的网格，网格中索引为 20 的线程将执行如下操作：</p>
<ul>
<li>对包含 500 个元素的数组的元素 20 执行相应运算</li>
<li>将其索引增加 250，使网格的大小达到 270</li>
<li>对包含 500 个元素的数组的元素 270 执行相应运算</li>
<li>将其索引增加 250，使网格的大小达到 520</li>
<li>由于 520 现已超出数组范围，因此线程将停止工作</li>
</ul>
<p>CUDA 提供一个可给出网格中线程块数的特殊变量：<code>gridDim.x</code>。然后计算网格中的总线程数，即网格中的线程块数乘以每个线程块中的线程数：<code>gridDim.x * blockDim.x</code>。带着这样的想法来看看以下核函数中网格跨度循环的详细示例：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global <span class="keyword">void</span> <span class="title">kernel</span><span class="params">(<span class="keyword">int</span> *a, <span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> indexWithinTheGrid = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">int</span> gridStride = gridDim.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = indexWithinTheGrid; i &lt; N; i += gridStride)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// do work on a[i];</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling"></a>Error Handling</h2><p>与在任何应用程序中一样，加速 CUDA 代码中的错误处理同样至关重要。即便不是大多数，也有许多 CUDA 函数（例如，<a href="http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY" target="_blank" rel="noopener">内存管理函数</a>）会返回类型为 <code>cudaError_t</code> 的值，该值可用于检查调用函数时是否发生错误。以下是对调用 <code>cudaMallocManaged</code> 函数执行错误处理的示例：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t err;</span><br><span class="line">err = cudaMallocManaged(&amp;a, N)                    <span class="comment">// Assume the existence of `a` and `N`.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)                           <span class="comment">// `cudaSuccess` is provided by CUDA.</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Error: %s\n"</span>, cudaGetErrorString(err)); <span class="comment">// `cudaGetErrorString` is provided by CUDA.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>启动定义为返回 <code>void</code> 的核函数后，将不会返回类型为 <code>cudaError_t</code> 的值。为检查启动核函数时是否发生错误（例如，如果启动配置错误），CUDA 提供 <code>cudaGetLastError</code> 函数，该函数会返回类型为 <code>cudaError_t</code> 的值。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This launch should cause an error, but the kernel itself</span></span><br><span class="line"><span class="comment"> * cannot return it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">someKernel&lt;&lt;&lt;<span class="number">1</span>, <span class="number">-1</span>&gt;&gt;&gt;();  <span class="comment">// -1 is not a valid number of threads.</span></span><br><span class="line"></span><br><span class="line">cudaError_t err;</span><br><span class="line">err = cudaGetLastError(); <span class="comment">// `cudaGetLastError` will return the error from above.</span></span><br><span class="line"><span class="keyword">if</span> (err != cudaSuccess)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Error: %s\n"</span>, cudaGetErrorString(err));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后，为捕捉异步错误（例如，在异步核函数执行期间），请务必检查后续同步 CUDA 运行时 API 调用所返回的状态（例如 <code>cudaDeviceSynchronize</code>）；如果之前启动的其中一个核函数失败，则将返回错误。</p>
<h3 id="CUDA-Error-Handling-Function"><a href="#CUDA-Error-Handling-Function" class="headerlink" title="CUDA Error Handling Function"></a>CUDA Error Handling Function</h3><p>创建一个包装 CUDA 函数调用的宏对于检查错误十分有用。以下是一个宏示例，您可以在余下练习中随时使用：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> cudaError_t <span class="title">checkCuda</span><span class="params">(cudaError_t result)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (result != cudaSuccess) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"CUDA Runtime Error: %s\n"</span>, cudaGetErrorString(result));</span><br><span class="line">    assert(result == cudaSuccess);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The macro can be wrapped around any function returning</span></span><br><span class="line"><span class="comment"> * a value of type `cudaError_t`.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">  checkCuda( cudaDeviceSynchronize() )</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Final-Exercise-Accelerate-Vector-Addition-Application"><a href="#Final-Exercise-Accelerate-Vector-Addition-Application" class="headerlink" title="Final Exercise: Accelerate Vector Addition Application"></a>Final Exercise: Accelerate Vector Addition Application</h3><p>下面的挑战将使您有机会运用在实验中学到的知识。其中涉及加速 CPU 向量加法程序，尽管该程序不甚复杂，但仍能让您有机会重点运用所学的借助 CUDA 加速 GPU 应用程序的相关知识。完成此练习后，如果您有富余时间并有意深究，可继续学习<em>高阶内容</em>部分以了解涉及更复杂代码库的一些挑战。</p>
<p>01-vector-add.cu包含一个可正常运作的 CPU 向量加法应用程序。加速其 <code>addVectorsInto</code> 函数，使之在 GPU 上以 CUDA 核函数运行并使其并行执行工作。鉴于需发生以下操作，如您遇到问题，请参阅解决方案。</p>
<ul>
<li>扩充 <code>addVectorsInto</code> 定义，使之成为 CUDA 核函数。</li>
<li>选择并使用有效的执行配置，以使 <code>addVectorsInto</code> 作为 CUDA 核函数启动。</li>
<li>更新内存分配，内存释放以反映主机和设备代码需要访问 3 个向量：<code>a</code>、<code>b</code> 和 <code>result</code>。</li>
<li>重构 <code>addVectorsInto</code> 的主体：将在单个线程内部启动，并且只需对输入向量执行单线程操作。确保线程从不尝试访问输入向量范围之外的元素，并注意线程是否需对输入向量的多个元素执行操作。</li>
<li>在 CUDA 代码可能以其他方式静默失败的位置添加错误处理。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;assert.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> cudaError_t <span class="title">checkCuda</span><span class="params">(cudaError_t result)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (result != cudaSuccess) &#123;</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"CUDA Runtime Error: %s\n"</span>, cudaGetErrorString(result));</span><br><span class="line">    assert(result == cudaSuccess);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">initWith</span><span class="params">(<span class="keyword">float</span> num, <span class="keyword">float</span> *a, <span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">  &#123;</span><br><span class="line">    a[i] = num;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">addVectorsInto</span><span class="params">(<span class="keyword">float</span> *result, <span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> idx = threadIdx.x + blockIdx.x * blockDim.x;    </span><br><span class="line">    <span class="keyword">int</span> gridStride = gridDim.x * blockDim.x;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = idx;i&lt;N;i+=gridStride)&#123;</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">          &#123;</span><br><span class="line">            result[i] = a[i] + b[i];</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">checkElementsAre</span><span class="params">(<span class="keyword">float</span> target, <span class="keyword">float</span> *<span class="built_in">array</span>, <span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">array</span>[i] != target)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"FAIL: array[%d] - %0.0f does not equal %0.0f\n"</span>, i, <span class="built_in">array</span>[i], target);</span><br><span class="line">      <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"SUCCESS! All values added correctly.\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">2</span>&lt;&lt;<span class="number">20</span>;</span><br><span class="line">  <span class="keyword">size_t</span> size = N * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> *a;</span><br><span class="line">  <span class="keyword">float</span> *b;</span><br><span class="line">  <span class="keyword">float</span> *c;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">  cudaMallocManaged(&amp;a,size);</span><br><span class="line">  cudaMallocManaged(&amp;b,size);</span><br><span class="line">  cudaMallocManaged(&amp;c,size);</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  initWith(<span class="number">3</span>, a, N);</span><br><span class="line">  initWith(<span class="number">4</span>, b, N);</span><br><span class="line">  initWith(<span class="number">0</span>, c, N);</span><br><span class="line"></span><br><span class="line">  addVectorsInto&lt;&lt;&lt;<span class="number">100</span>,<span class="number">100</span>&gt;&gt;&gt;(c, a, b, N);</span><br><span class="line">  <span class="comment">//cudaDeviceSynchronize();</span></span><br><span class="line">  checkCuda( cudaDeviceSynchronize() );</span><br><span class="line"></span><br><span class="line">  checkElementsAre(<span class="number">7</span>, c, N);</span><br><span class="line"></span><br><span class="line">  cudaFree(a);</span><br><span class="line">  cudaFree(b);</span><br><span class="line">  cudaFree(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Grids-and-Blocks-of-2-and-3-Dimensions"><a href="#Grids-and-Blocks-of-2-and-3-Dimensions" class="headerlink" title="Grids and Blocks of 2 and 3 Dimensions"></a>Grids and Blocks of 2 and 3 Dimensions</h2><p>可以将网格和线程块定义为最多具有 3 个维度。使用多个维度定义网格和线程块绝不会对其性能造成任何影响，但这在处理具有多个维度的数据时可能非常有用，例如 2D 矩阵。如要定义二维或三维网格或线程块，可以使用 CUDA 的 <code>dim3</code> 类型，即如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">threads_per_block</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">number_of_blocks</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">someKernel&lt;&lt;&lt;number_of_blocks, threads_per_block&gt;&gt;&gt;();</span><br></pre></td></tr></table></figure>

<p>鉴于以上示例，<code>someKernel</code> 内部的变量 <code>gridDim.x</code>、<code>gridDim.y</code>、<code>blockDim.x</code> 和 <code>blockDim.y</code> 均将等于 <code>16</code>。</p>
<h3 id="Exercise-Accelerate-2D-Matrix-Multiply-Application"><a href="#Exercise-Accelerate-2D-Matrix-Multiply-Application" class="headerlink" title="Exercise: Accelerate 2D Matrix Multiply Application"></a>Exercise: Accelerate 2D Matrix Multiply Application</h3><p>文件 <a href="http://ec2-3-89-85-142.compute-1.amazonaws.com/DdJxiLJo/edit/tasks/task1/task/01_AC_CUDA_C-zh/08-matrix-multiply/01-matrix-multiply-2d.cu" target="_blank" rel="noopener"><code>01-matrix-multiply-2d.cu</code></a> 包含一个功能齐全的主机函数 <code>matrixMulCPU</code>。您的任务是扩建 CUDA 核函数 <code>matrixMulGPU</code>。源代码将使用这两个函数执行矩阵乘法，并比较它们的答案以验证您编写的 CUDA 核函数是否正确。使用以下指南获得操作支持，如您遇到问题，请参阅 <a href="http://ec2-3-89-85-142.compute-1.amazonaws.com/DdJxiLJo/edit/tasks/task1/task/01_AC_CUDA_C-zh/08-matrix-multiply/solutions/01-matrix-multiply-2d-solution.cu" target="_blank" rel="noopener">解决方案</a>：</p>
<ul>
<li>您将需创建执行配置，其参数均为 <code>dim3</code> 值，且 <code>x</code> 和 <code>y</code> 维度均设为大于 <code>1</code>。</li>
<li>在核函数主体内部，您将需要按照惯例在网格内建立所运行线程的唯一索引，但应为线程建立两个索引：一个用于网格的 x 轴，另一个用于网格的 y 轴。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N  64</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">matrixMulGPU</span><span class="params">( <span class="keyword">int</span> * a, <span class="keyword">int</span> * b, <span class="keyword">int</span> * c )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> val = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> row = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">int</span> col = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (row &lt; N &amp;&amp; col &lt; N)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> k = <span class="number">0</span>; k &lt; N; ++k )</span><br><span class="line">      val += a[row * N + k] * b[k * N + col];</span><br><span class="line">    c[row * N + col] = val;</span><br><span class="line">  &#125;</span><br><span class="line">   </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This CPU function already works, and will run to create a solution matrix</span></span><br><span class="line"><span class="comment"> * against which to verify your work building out the matrixMulGPU kernel.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">matrixMulCPU</span><span class="params">( <span class="keyword">int</span> * a, <span class="keyword">int</span> * b, <span class="keyword">int</span> * c )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> val = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> row = <span class="number">0</span>; row &lt; N; ++row )</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> col = <span class="number">0</span>; col &lt; N; ++col )</span><br><span class="line">    &#123;</span><br><span class="line">      val = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> ( <span class="keyword">int</span> k = <span class="number">0</span>; k &lt; N; ++k )</span><br><span class="line">        val += a[row * N + k] * b[k * N + col];</span><br><span class="line">      c[row * N + col] = val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> *a, *b, *c_cpu, *c_gpu; <span class="comment">// Allocate a solution matrix for both the CPU and the GPU operations</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> <span class="built_in">size</span> = N * N * <span class="keyword">sizeof</span> (<span class="keyword">int</span>); <span class="comment">// Number of bytes of an N x N matrix</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Allocate memory</span></span><br><span class="line">  cudaMallocManaged (&amp;a, <span class="built_in">size</span>);</span><br><span class="line">  cudaMallocManaged (&amp;b, <span class="built_in">size</span>);</span><br><span class="line">  cudaMallocManaged (&amp;c_cpu, <span class="built_in">size</span>);</span><br><span class="line">  cudaMallocManaged (&amp;c_gpu, <span class="built_in">size</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialize memory; create 2D matrices</span></span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> row = <span class="number">0</span>; row &lt; N; ++row )</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> col = <span class="number">0</span>; col &lt; N; ++col )</span><br><span class="line">    &#123;</span><br><span class="line">      a[row*N + col] = row;</span><br><span class="line">      b[row*N + col] = col+<span class="number">2</span>;</span><br><span class="line">      c_cpu[row*N + col] = <span class="number">0</span>;</span><br><span class="line">      c_gpu[row*N + col] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Assign `threads_per_block` and `number_of_blocks` 2D values</span></span><br><span class="line"><span class="comment">   * that can be used in matrixMulGPU above.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="function">dim3 <span class="title">threads_per_block</span><span class="params">(<span class="number">16</span>,<span class="number">16</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">number_of_blocks</span><span class="params">(<span class="number">4</span>,<span class="number">4</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">  matrixMulGPU &lt;&lt;&lt; number_of_blocks, threads_per_block &gt;&gt;&gt; ( a, b, c_gpu );</span><br><span class="line"></span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Call the CPU version to check our work</span></span><br><span class="line">  matrixMulCPU( a, b, c_cpu );</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Compare the two answers to make sure they are equal</span></span><br><span class="line">  <span class="keyword">bool</span> error = <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> row = <span class="number">0</span>; row &lt; N &amp;&amp; !error; ++row )</span><br><span class="line">    <span class="keyword">for</span>( <span class="keyword">int</span> col = <span class="number">0</span>; col &lt; N &amp;&amp; !error; ++col )</span><br><span class="line">      <span class="keyword">if</span> (c_cpu[row * N + col] != c_gpu[row * N + col])</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"FOUND ERROR at c[%d][%d]\n"</span>, row, col);</span><br><span class="line">        error = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">  <span class="keyword">if</span> (!error)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Success!\n"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Free all our allocated memory</span></span><br><span class="line">  cudaFree(a); cudaFree(b);</span><br><span class="line">  cudaFree( c_cpu ); cudaFree( c_gpu );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Exercise-Accelerate-A-Thermal-Conductivity-Application"><a href="#Exercise-Accelerate-A-Thermal-Conductivity-Application" class="headerlink" title="Exercise: Accelerate A Thermal Conductivity Application"></a>Exercise: Accelerate A Thermal Conductivity Application</h3><p>在下面的练习中，您将为模拟金属银二维热传导的应用程序执行加速操作。</p>
<p>将 <a href="http://ec2-3-84-208-168.compute-1.amazonaws.com/3riRC33t/edit/tasks/task1/task/01_AC_CUDA_C-zh/09-heat/01-heat-conduction.cu" target="_blank" rel="noopener"><code>01-heat-conduction.cu</code></a> 内的 <code>step_kernel_mod</code> 函数转换为在 GPU 上执行，并修改 <code>main</code> 函数以恰当分配在 CPU 和 GPU 上使用的数据。<code>step_kernel_ref</code> 函数在 CPU 上执行并用于检查错误。由于此代码涉及浮点计算，因此不同的处理器甚或同一处理器上的简单重排操作都可能导致结果略有出入。为此，错误检查代码会使用错误阈值，而非查找完全匹配。如您遇到问题，请参阅 <a href="http://ec2-3-84-208-168.compute-1.amazonaws.com/3riRC33t/edit/tasks/task1/task/01_AC_CUDA_C-zh/09-heat/solutions/01-heat-conduction-solution.cu" target="_blank" rel="noopener">解决方案</a>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Simple define to index into a 1D array from 2D space</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> I2D(num, c, r) ((r)*(num)+(c))</span></span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">step_kernel_mod</span><span class="params">(<span class="keyword">int</span> ni, <span class="keyword">int</span> nj, <span class="keyword">float</span> fact, <span class="keyword">float</span>* temp_in, <span class="keyword">float</span>* temp_out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i00, im10, ip10, i0m1, i0p1;</span><br><span class="line">  <span class="keyword">float</span> d2tdx2, d2tdy2;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> j = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">  <span class="keyword">int</span> i = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// loop over all points in domain (except boundary)</span></span><br><span class="line">  <span class="keyword">if</span> (j &gt; <span class="number">0</span> &amp;&amp; i &gt; <span class="number">0</span> &amp;&amp; j &lt; nj<span class="number">-1</span> &amp;&amp; i &lt; ni<span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="comment">// find indices into linear memory</span></span><br><span class="line">    <span class="comment">// for central point and neighbours</span></span><br><span class="line">    i00 = I2D(ni, i, j);</span><br><span class="line">    im10 = I2D(ni, i<span class="number">-1</span>, j);</span><br><span class="line">    ip10 = I2D(ni, i+<span class="number">1</span>, j);</span><br><span class="line">    i0m1 = I2D(ni, i, j<span class="number">-1</span>);</span><br><span class="line">    i0p1 = I2D(ni, i, j+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// evaluate derivatives</span></span><br><span class="line">    d2tdx2 = temp_in[im10]<span class="number">-2</span>*temp_in[i00]+temp_in[ip10];</span><br><span class="line">    d2tdy2 = temp_in[i0m1]<span class="number">-2</span>*temp_in[i00]+temp_in[i0p1];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update temperatures</span></span><br><span class="line">    temp_out[i00] = temp_in[i00]+fact*(d2tdx2 + d2tdy2);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">step_kernel_ref</span><span class="params">(<span class="keyword">int</span> ni, <span class="keyword">int</span> nj, <span class="keyword">float</span> fact, <span class="keyword">float</span>* temp_in, <span class="keyword">float</span>* temp_out)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> i00, im10, ip10, i0m1, i0p1;</span><br><span class="line">  <span class="keyword">float</span> d2tdx2, d2tdy2;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">// loop over all points in domain (except boundary)</span></span><br><span class="line">  <span class="keyword">for</span> ( <span class="keyword">int</span> j=<span class="number">1</span>; j &lt; nj<span class="number">-1</span>; j++ ) &#123;</span><br><span class="line">    <span class="keyword">for</span> ( <span class="keyword">int</span> i=<span class="number">1</span>; i &lt; ni<span class="number">-1</span>; i++ ) &#123;</span><br><span class="line">      <span class="comment">// find indices into linear memory</span></span><br><span class="line">      <span class="comment">// for central point and neighbours</span></span><br><span class="line">      i00 = I2D(ni, i, j);</span><br><span class="line">      im10 = I2D(ni, i<span class="number">-1</span>, j);</span><br><span class="line">      ip10 = I2D(ni, i+<span class="number">1</span>, j);</span><br><span class="line">      i0m1 = I2D(ni, i, j<span class="number">-1</span>);</span><br><span class="line">      i0p1 = I2D(ni, i, j+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// evaluate derivatives</span></span><br><span class="line">      d2tdx2 = temp_in[im10]<span class="number">-2</span>*temp_in[i00]+temp_in[ip10];</span><br><span class="line">      d2tdy2 = temp_in[i0m1]<span class="number">-2</span>*temp_in[i00]+temp_in[i0p1];</span><br><span class="line"></span><br><span class="line">      <span class="comment">// update temperatures</span></span><br><span class="line">      temp_out[i00] = temp_in[i00]+fact*(d2tdx2 + d2tdy2);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> istep;</span><br><span class="line">  <span class="keyword">int</span> nstep = <span class="number">200</span>; <span class="comment">// number of time steps</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Specify our 2D dimensions</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> ni = <span class="number">200</span>;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> nj = <span class="number">100</span>;</span><br><span class="line">  <span class="keyword">float</span> tfac = <span class="number">8.418e-5</span>; <span class="comment">// thermal diffusivity of silver</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> *temp1_ref, *temp2_ref, *temp1, *temp2, *temp_tmp;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> <span class="built_in">size</span> = ni * nj * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);</span><br><span class="line"></span><br><span class="line">  temp1_ref = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="built_in">size</span>);</span><br><span class="line">  temp2_ref = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="built_in">size</span>);</span><br><span class="line">  cudaMallocManaged(&amp;temp1, <span class="built_in">size</span>);</span><br><span class="line">  cudaMallocManaged(&amp;temp2, <span class="built_in">size</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Initialize with random data</span></span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ni*nj; ++i) &#123;</span><br><span class="line">    temp1_ref[i] = temp2_ref[i] = temp1[i] = temp2[i] = (<span class="keyword">float</span>)rand()/(<span class="keyword">float</span>)(RAND_MAX/<span class="number">100.0f</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Execute the CPU-only reference version</span></span><br><span class="line">  <span class="keyword">for</span> (istep=<span class="number">0</span>; istep &lt; nstep; istep++) &#123;</span><br><span class="line">    step_kernel_ref(ni, nj, tfac, temp1_ref, temp2_ref);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// swap the temperature pointers</span></span><br><span class="line">    temp_tmp = temp1_ref;</span><br><span class="line">    temp1_ref = temp2_ref;</span><br><span class="line">    temp2_ref= temp_tmp;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">dim3 <span class="title">tblocks</span><span class="params">(<span class="number">32</span>, <span class="number">16</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  <span class="function">dim3 <span class="title">grid</span><span class="params">((nj/tblocks.x)+<span class="number">1</span>, (ni/tblocks.y)+<span class="number">1</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  cudaError_t ierrSync, ierrAsync;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Execute the modified version using same data</span></span><br><span class="line">  <span class="keyword">for</span> (istep=<span class="number">0</span>; istep &lt; nstep; istep++) &#123;</span><br><span class="line">    step_kernel_mod&lt;&lt;&lt; grid, tblocks &gt;&gt;&gt;(ni, nj, tfac, temp1, temp2);</span><br><span class="line"></span><br><span class="line">    ierrSync = cudaGetLastError();</span><br><span class="line">    ierrAsync = cudaDeviceSynchronize(); <span class="comment">// Wait for the GPU to finish</span></span><br><span class="line">    <span class="keyword">if</span> (ierrSync != cudaSuccess) &#123; <span class="built_in">printf</span>(<span class="string">"Sync error: %s\n"</span>, cudaGetErrorString(ierrSync)); &#125;</span><br><span class="line">    <span class="keyword">if</span> (ierrAsync != cudaSuccess) &#123; <span class="built_in">printf</span>(<span class="string">"Async error: %s\n"</span>, cudaGetErrorString(ierrAsync)); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// swap the temperature pointers</span></span><br><span class="line">    temp_tmp = temp1;</span><br><span class="line">    temp1 = temp2;</span><br><span class="line">    temp2= temp_tmp;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">float</span> maxError = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// Output should always be stored in the temp1 and temp1_ref at this point</span></span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ni*nj; ++i ) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">abs</span>(temp1[i]-temp1_ref[i]) &gt; maxError) &#123; maxError = <span class="built_in">abs</span>(temp1[i]-temp1_ref[i]); &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Check and see if our maxError is greater than an error bound</span></span><br><span class="line">  <span class="keyword">if</span> (maxError &gt; <span class="number">0.0005f</span>)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Problem! The Max Error of %.5f is NOT within acceptable bounds.\n"</span>, maxError);</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"The Max Error of %.5f is within acceptable bounds.\n"</span>, maxError);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">free</span>( temp1_ref );</span><br><span class="line">  <span class="built_in">free</span>( temp2_ref );</span><br><span class="line">  cudaFree( temp1 );</span><br><span class="line">  cudaFree( temp2 );</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">==<span class="number">188</span>== NVPROF <span class="keyword">is</span> profiling process <span class="number">188</span>, command: ./single-thread-vector-add</span><br><span class="line">Success! All values calculated correctly.</span><br><span class="line">==<span class="number">188</span>== Profiling application: ./single-thread-vector-add</span><br><span class="line">==<span class="number">188</span>== Profiling result:</span><br><span class="line">            Type  Time(%)      Time     Calls       Avg       Min       Max  Name</span><br><span class="line"> GPU activities:  <span class="number">100.00</span>%  <span class="number">2.37011</span>s         <span class="number">1</span>  <span class="number">2.37011</span>s  <span class="number">2.37011</span>s  <span class="number">2.37011</span>s  addVectorsInto(<span class="built_in">float</span>*, <span class="built_in">float</span>*, <span class="built_in">float</span>*, <span class="built_in">int</span>)</span><br><span class="line">      API calls:   <span class="number">57.28</span>%  <span class="number">2.37013</span>s         <span class="number">1</span>  <span class="number">2.37013</span>s  <span class="number">2.37013</span>s  <span class="number">2.37013</span>s  cudaDeviceSynchronize</span><br><span class="line">                   <span class="number">42.13</span>%  <span class="number">1.74342</span>s         <span class="number">3</span>  <span class="number">581.14</span>ms  <span class="number">19.768</span>us  <span class="number">1.74336</span>s  cudaMallocManaged</span><br><span class="line">                    <span class="number">0.56</span>%  <span class="number">23.287</span>ms         <span class="number">3</span>  <span class="number">7.7625</span>ms  <span class="number">7.0587</span>ms  <span class="number">9.0555</span>ms  cudaFree</span><br><span class="line">                    <span class="number">0.02</span>%  <span class="number">704.50</span>us         <span class="number">1</span>  <span class="number">704.50</span>us  <span class="number">704.50</span>us  <span class="number">704.50</span>us  cuDeviceTotalMem</span><br><span class="line">                    <span class="number">0.01</span>%  <span class="number">216.34</span>us        <span class="number">94</span>  <span class="number">2.3010</span>us     <span class="number">606</span>ns  <span class="number">50.785</span>us  cuDeviceGetAttribute</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">76.115</span>us         <span class="number">1</span>  <span class="number">76.115</span>us  <span class="number">76.115</span>us  <span class="number">76.115</span>us  cudaLaunch</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">14.602</span>us         <span class="number">1</span>  <span class="number">14.602</span>us  <span class="number">14.602</span>us  <span class="number">14.602</span>us  cuDeviceGetName</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">10.685</span>us         <span class="number">4</span>  <span class="number">2.6710</span>us     <span class="number">676</span>ns  <span class="number">7.6680</span>us  cudaSetupArgument</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">4.5370</span>us         <span class="number">1</span>  <span class="number">4.5370</span>us  <span class="number">4.5370</span>us  <span class="number">4.5370</span>us  cudaConfigureCall</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">3.6480</span>us         <span class="number">3</span>  <span class="number">1.2160</span>us     <span class="number">646</span>ns  <span class="number">1.9600</span>us  cuDeviceGetCount</span><br><span class="line">                    <span class="number">0.00</span>%  <span class="number">2.0180</span>us         <span class="number">2</span>  <span class="number">1.0090</span>us     <span class="number">693</span>ns  <span class="number">1.3250</span>us  cuDeviceGet</span><br><span class="line">                    <span class="number">0.00</span>%     <span class="number">973</span>ns         <span class="number">1</span>     <span class="number">973</span>ns     <span class="number">973</span>ns     <span class="number">973</span>ns  cudaGetLastError</span><br><span class="line"></span><br><span class="line">==<span class="number">188</span>== Unified Memory profiling result:</span><br><span class="line">Device <span class="string">"Tesla V100-SXM2-16GB (0)"</span></span><br><span class="line">   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name</span><br><span class="line">    <span class="number">2304</span>  <span class="number">170.67</span>KB  <span class="number">4.0000</span>KB  <span class="number">0.9961</span>MB  <span class="number">384.0000</span>MB  <span class="number">42.44723</span>ms  Host To Device</span><br><span class="line">     <span class="number">768</span>  <span class="number">170.67</span>KB  <span class="number">4.0000</span>KB  <span class="number">0.9961</span>MB  <span class="number">128.0000</span>MB  <span class="number">11.30275</span>ms  Device To Host</span><br><span class="line">     <span class="number">768</span>         -         -         -           -  <span class="number">110.5986</span>ms  Gpu page fault groups</span><br><span class="line">Total CPU Page faults: <span class="number">1536</span></span><br></pre></td></tr></table></figure>

<p><img src="1584244854962.png" alt="1584244854962"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"timer.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"check.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SOFTENING 1e-9f</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Each body contains x, y, and z coordinate positions,</span></span><br><span class="line"><span class="comment"> * as well as velocities in the x, y, and z directions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> <span class="keyword">float</span> x, y, z, vx, vy, vz; &#125; Body;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Do not modify this function. A constraint of this exercise is</span></span><br><span class="line"><span class="comment"> * that it remain a host function.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">randomizeBodies</span><span class="params">(<span class="keyword">float</span> *data, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">    data[i] = <span class="number">2.0f</span> * (rand() / (<span class="keyword">float</span>)RAND_MAX) - <span class="number">1.0f</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * This function calculates the gravitational impact of all bodies in the system</span></span><br><span class="line"><span class="comment"> * on all others, but does not update their positions.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line">__global__</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bodyForce</span><span class="params">(Body *p, <span class="keyword">float</span> dt, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = index; i &lt; n; i += stride) &#123;</span><br><span class="line">    <span class="keyword">float</span> Fx = <span class="number">0.0f</span>; <span class="keyword">float</span> Fy = <span class="number">0.0f</span>; <span class="keyword">float</span> Fz = <span class="number">0.0f</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; n; j++) &#123;</span><br><span class="line">      <span class="keyword">float</span> dx = p[j].x - p[i].x;</span><br><span class="line">      <span class="keyword">float</span> dy = p[j].y - p[i].y;</span><br><span class="line">      <span class="keyword">float</span> dz = p[j].z - p[i].z;</span><br><span class="line">      <span class="keyword">float</span> distSqr = dx*dx + dy*dy + dz*dz + SOFTENING;</span><br><span class="line">      <span class="keyword">float</span> invDist = rsqrtf(distSqr);</span><br><span class="line">      <span class="keyword">float</span> invDist3 = invDist * invDist * invDist;</span><br><span class="line"></span><br><span class="line">      Fx += dx * invDist3; Fy += dy * invDist3; Fz += dz * invDist3;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    p[i].vx += dt*Fx; </span><br><span class="line">    p[i].vy += dt*Fy; </span><br><span class="line">    p[i].vz += dt*Fz; </span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="keyword">void</span> <span class="title">add</span><span class="params">(Body*p, <span class="keyword">float</span> dt,<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> index = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">  <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = index; i &lt; n; i += stride) &#123;</span><br><span class="line">    p[i].x += p[i].vx*dt;</span><br><span class="line">    p[i].y += p[i].vy*dt;</span><br><span class="line">    p[i].z += p[i].vz*dt;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> argc, <span class="keyword">const</span> <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> deviceId;</span><br><span class="line">  <span class="keyword">int</span> numberOfSMs;</span><br><span class="line"></span><br><span class="line">  cudaGetDevice(&amp;deviceId);</span><br><span class="line">  cudaDeviceGetAttribute(&amp;numberOfSMs, cudaDevAttrMultiProcessorCount, deviceId);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Do not change the value for `nBodies` here. If you would like to modify it,</span></span><br><span class="line"><span class="comment">   * pass values into the command line.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> nBodies = <span class="number">2</span>&lt;&lt;<span class="number">11</span>;</span><br><span class="line">  <span class="keyword">int</span> salt = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">1</span>) nBodies = <span class="number">2</span>&lt;&lt;atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * This salt is for assessment reasons. Tampering with it will result in automatic failure.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (argc &gt; <span class="number">2</span>) salt = atoi(argv[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">float</span> dt = <span class="number">0.01f</span>; <span class="comment">// time step</span></span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">int</span> nIters = <span class="number">10</span>;  <span class="comment">// simulation iterations</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> bytes = nBodies * <span class="keyword">sizeof</span>(Body);</span><br><span class="line">  <span class="keyword">float</span> *buf;</span><br><span class="line"></span><br><span class="line">  cudaMallocManaged(&amp;buf, bytes);</span><br><span class="line">  <span class="comment">//cudaMemPrefetchAsync(buf, bytes, deviceId);</span></span><br><span class="line"></span><br><span class="line">  Body *p = (Body*)buf;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * As a constraint of this exercise, `randomizeBodies` must remain a host function.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  randomizeBodies(buf, <span class="number">6</span> * nBodies); <span class="comment">// Init pos / vel data</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">size_t</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line">  <span class="keyword">size_t</span> numberOfBlocks = <span class="number">32</span> * numberOfSMs;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">double</span> totalTime = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * This simulation will run for 10 cycles of time, calculating gravitational</span></span><br><span class="line"><span class="comment">   * interaction amongst bodies, and adjusting their positions to reflect.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*******************************************************************/</span></span><br><span class="line">  <span class="comment">// Do not modify these 2 lines of code.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> iter = <span class="number">0</span>; iter &lt; nIters; iter++) &#123;</span><br><span class="line">    StartTimer();</span><br><span class="line">  <span class="comment">/*******************************************************************/</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * You will likely wish to refactor the work being done in `bodyForce`,</span></span><br><span class="line"><span class="comment">   * as well as the work to integrate the positions.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  bodyForce&lt;&lt;&lt; numberOfBlocks, threadsPerBlock &gt;&gt;&gt;(p, dt, nBodies); <span class="comment">// compute interbody forces  </span></span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">  add&lt;&lt;&lt; numberOfBlocks, threadsPerBlock &gt;&gt;&gt;(p, dt, nBodies);</span><br><span class="line">  <span class="comment">// Do not modify the code in this section.</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">double</span> tElapsed = GetTimer() / <span class="number">1000.0</span>;</span><br><span class="line">    totalTime += tElapsed;</span><br><span class="line">  &#125;</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">double</span> avgTime = totalTime / (<span class="keyword">double</span>)(nIters);</span><br><span class="line">  <span class="keyword">float</span> billionsOfOpsPerSecond = <span class="number">1e-9</span> * nBodies * nBodies / avgTime;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> ASSESS</span></span><br><span class="line">  checkPerformance(buf, billionsOfOpsPerSecond, salt);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">  checkAccuracy(buf, nBodies);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"%d Bodies: average %0.3f Billion Interactions / second\n"</span>, nBodies, billionsOfOpsPerSecond);</span><br><span class="line">  salt += <span class="number">1</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  <span class="comment">/*******************************************************************/</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Feel free to modify code below.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"></span><br><span class="line">  cudaFree(buf);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>复制工作目录（上文高亮部分），并替换以下代码块中的 ##FIXME##。完成替换之后，执行此单元 (Shift+Enter) 以将其存储到变量 MODEL_JOB_DIR 中</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MODEL_JOB_DIR = '/dli/data/digits/20180301-185638-e918'  ## Remember to set this to be the job directory for your model</span><br><span class="line">!ls $MODEL_JOB_DIR</span><br></pre></td></tr></table></figure>

<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">caffe_output</span><span class="selector-class">.log</span>   <span class="selector-tag">snapshot_iter_735</span><span class="selector-class">.caffemodel</span>   <span class="selector-tag">status</span><span class="selector-class">.pickle</span></span><br><span class="line"><span class="selector-tag">deploy</span><span class="selector-class">.prototxt</span>    <span class="selector-tag">snapshot_iter_735</span><span class="selector-class">.solverstate</span>  <span class="selector-tag">train_val</span><span class="selector-class">.prototxt</span></span><br><span class="line"><span class="selector-tag">original</span><span class="selector-class">.prototxt</span>  <span class="selector-tag">solver</span><span class="selector-class">.prototxt</span></span><br></pre></td></tr></table></figure>



<p>复制并粘贴成功后，您将看到该目录中所有文件的列表。如果以下说明与您所见不符，请检查复制/粘贴操作是否成功。</p>
<p>我们的“模型”同样包含两个文件：网络结构和权重。</p>
<p>网络结构文件名为 <code>deploy.prototxt</code>，权重则在最新生成的快照文件中（文件名为 <code>snapshot_iter_#.caffemodel.</code>）在本例中，快照编号 735 包含 5 次训练全部完成后习得的权重。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ARCHITECTURE = MODEL_JOB_DIR + '/' + 'deploy.prototxt'</span><br><span class="line">WEIGHTS = MODEL_JOB_DIR + '/' + 'snapshot_iter_735.caffemodel'</span><br><span class="line"><span class="built_in">print</span> (<span class="string">"Filepath to Architecture = "</span> + ARCHITECTURE)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Filepath to weights = "</span>+ WEIGHTS)</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Filepath to Architecture = /dli/data/digits/<span class="number">20180301</span><span class="number">-185638</span>-e918/deploy.prototxt</span><br><span class="line">Filepath to weights = /dli/data/digits/<span class="number">20180301</span><span class="number">-185638</span>-e918/snapshot_iter_735.caffemodel</span><br></pre></td></tr></table></figure>



<p>接下来，我们需要确保正在构建的程序可以读取并处理这些文件。在部署中，我们需安装模型训练时所用的深度学习框架，以便能够解析它们。稍后，我们会在本课程中学习如何将模型部署至无需安装框架的环境中。我们还需使用 GPU的并行处理能力。我们的模型包含数十万次操作运算，可通过并行计算予以显著加速。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line">caffe.set_mode_gpu()</span><br></pre></td></tr></table></figure>

<p>接下来，我们将创建名为“net”的“分类器”对象。工作流程越常见，您就越容易利用现有工具创建项目。在本例中，图像分类十分常见，因此下一个代码块只需使用网络结构文件和权重文件以及部分数据，简化了常见操作。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Initialize the Caffe model <span class="keyword">using</span> the model trained in DIGITS</span><br><span class="line">net = caffe.Classifier(ARCHITECTURE, WEIGHTS,  </span><br><span class="line">                       channel_swap =(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>), #Color images have three channels, Red, Green, <span class="keyword">and</span> Blue.</span><br><span class="line">                       raw_scale=<span class="number">255</span>) #Each pixel value is a number between <span class="number">0</span> <span class="keyword">and</span> <span class="number">255</span></span><br><span class="line">                       #Each <span class="string">"channel"</span> of our images are <span class="number">256</span> x <span class="number">256</span></span><br></pre></td></tr></table></figure>

<p>“分类器”这个类包括一种“预测”方法，该方法会提取上文所定义图像的输入，输出该图像属于每一类别的概率。</p>
<p>创建预期输入：预处理)</p>
<p>我们首先来进行一项简单的任务：尝试从数据集中正确分类已标记图像。我们可以通过运行下方单元来加载图像并进行查看。</p>
<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot <span class="keyword">as</span> plt #matplotlib.pyplot allows us <span class="keyword">to</span> visualize results</span><br><span class="line">input_image= caffe.io.load<span class="constructor">_image('<span class="operator">/</span><span class="params">dli</span><span class="operator">/</span><span class="params">data</span><span class="operator">/</span><span class="params">dogscats</span><span class="operator">/</span><span class="params">train</span><span class="operator">/</span><span class="params">cats</span><span class="operator">/</span><span class="params">cat</span>.10941.<span class="params">jpg</span>')</span></span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show<span class="literal">()</span></span><br></pre></td></tr></table></figure>

<p>虽然我们已获得此图像，但它并非网络所期望的“输入”。</p>
<p>在准备推理数据时，我们需遵循一条黄金法则：</p>
<blockquote>
<p>训练前的所有操作均需在推理之前完成</p>
</blockquote>
<p>在上一节中，您看到了 DIGITS 在训练模型时生成的文件。而在本节，我们将检测 DIGITS 在创建数据集时生成的文件。</p>
<p>当您从模型页面“狗和猫”中选择数据集及/或从 DIGITS“数据集”选项卡下选择数据集时，便可找到所训练<strong>数据集</strong>的工作目录。工作目录与模型所在位置相同，只不过编号应会有所不同。</p>
<p>使用此工作目录替换 ##FIXME##，并执行下方代码以将 DATA_JOB_DIR 设置为正确的文件路径，然后检查此路径下的内容：</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">DATA_JOB_DIR</span> = <span class="string">'/dli/data/digits/20180222-165843-ada0'</span>  <span class="comment">## Remember to set this to be the job directory for your model</span></span><br><span class="line">!ls <span class="variable">$DATA_JOB_DIR</span></span><br></pre></td></tr></table></figure>

<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">create_train_db</span><span class="selector-class">.log</span>  <span class="selector-tag">labels</span><span class="selector-class">.txt</span>        <span class="selector-tag">mean</span><span class="selector-class">.jpg</span>       <span class="selector-tag">train</span><span class="selector-class">.txt</span>  <span class="selector-tag">val</span><span class="selector-class">.txt</span></span><br><span class="line"><span class="selector-tag">create_val_db</span><span class="selector-class">.log</span>    <span class="selector-tag">mean</span><span class="selector-class">.binaryproto</span>  <span class="selector-tag">status</span><span class="selector-class">.pickle</span>  <span class="selector-tag">train_db</span>	 <span class="selector-tag">val_db</span></span><br></pre></td></tr></table></figure>



<p>同样，此处会提供超过您目前所需的更多信息。您<em>能够</em>了解有关数据科学和数据准备的海量信息，并会在解决各类深度学习问题后获得更清晰的认知。在本例中，DIGITS 在训练之前执行了两个步骤。我们称之为<em>预处理</em>。</p>
<p>1) DIGITS 将图像调整为 256X256 大小的彩色图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">input_image=cv2.resize(input_image, (<span class="number">256</span>, <span class="number">256</span>), <span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>2) DIGITS 通过从每张图像中减除均值图像以将图像<em>标准化</em>，以此减少训练所需的计算量。</p>
<p>加载均值图像，并将其从以下测试图像中减除：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mean_image = caffe.io.load_image(DATA_JOB_DIR+<span class="string">'/mean.jpg'</span>)</span><br><span class="line">ready_image = input_image-mean_image</span><br></pre></td></tr></table></figure>

<p>我们现已取得原始数据，并已将其转换为网络所期望的数据。接下来，我们来看一下网络所创建的输出。</p>
<h2 id="前向传播：使用您的模型"><a href="#前向传播：使用您的模型" class="headerlink" title="前向传播：使用您的模型"></a>前向传播：使用您的模型</h2><p>这就是我们的关注所在。我们来看看这个函数： <code>prediction = net.predict([grid_square])</code>.</p>
<p>与其他任一 <a href="https://www.khanacademy.org/computing/computer-programming/programming#functions" target="_blank" rel="noopener">函数</a> 类似，<code>net.predict</code> 也会传递输入 <code>ready_image</code>，并返回输出 <code>prediction</code>。但与其他函数不同，该函数并不遵循一组步骤，而是逐层开展矩阵数学运算，以将图像转换为概率向量。</p>
<p>运行下方单元，以查看对以上已标记数据作出的预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make prediction</span></span><br><span class="line">prediction = net.predict([ready_image])</span><br><span class="line"><span class="keyword">print</span> prediction</span><br><span class="line">--[[ <span class="number">0.70993775</span>  <span class="number">0.29006225</span>]]</span><br></pre></td></tr></table></figure>

<p>结果很有趣，但并未包含太多信息。我们的网络获取到 256x256 大小的标准化彩色图像，并生成一个长度为 2 的向量。</p>
<h2 id="生成有用的输出：后处理"><a href="#生成有用的输出：后处理" class="headerlink" title="生成有用的输出：后处理"></a>生成有用的输出：后处理</h2><p>此时，我们便可真正构建想要的任何内容。而唯一的局限在于您的编程经验。在进行创意操作之前，我们先来构建一些基本内容。此代码将能确定网络输出“狗”的概率是否高于“猫”。若为此，当狗接近模拟的狗门时，其将显示适当的图像。否则，若网络确定门前是只猫，图像便会呈现我们希望看到的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Input image:"</span>)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Output:"</span>)</span><br><span class="line"><span class="keyword">if</span> prediction.argmax()==<span class="number">0</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Sorry cat:( https://media.giphy.com/media/jb8aFEQk3tADS/giphy.gif"</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Welcome dog! https://www.flickr.com/photos/aidras/5379402670"</span></span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2020/03/29/jewqLO3yNzpb8Fm.png" alt="1584367324218"></p>
<p>此时，我们已在此处做好所有准备工作，您现在可以对狗门可能会看到的图像进行测试。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##Create an input our network expects</span></span><br><span class="line">input_image= caffe.io.load_image(<span class="string">'/dli/data/fromnest.PNG'</span>)</span><br><span class="line"><span class="attribute">input_image</span>=cv2.resize(input_image, (256, 256), 0,0)</span><br><span class="line">ready_image = input_image-mean_image</span><br><span class="line"><span class="comment">##Treat our network as a function that takes an input and generates an output</span></span><br><span class="line">prediction = net.predict([ready_image])</span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">"Input Image:"</span>)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="builtin-name">print</span>(prediction)</span><br><span class="line"><span class="comment">##Create a useful output</span></span><br><span class="line"><span class="builtin-name">print</span>(<span class="string">"Output:"</span>)</span><br><span class="line"><span class="keyword">if</span> prediction.argmax()==0:</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Sorry cat:( https://media.giphy.com/media/jb8aFEQk3tADS/giphy.gif"</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="builtin-name">print</span> <span class="string">"Welcome dog! https://www.flickr.com/photos/aidras/5379402670"</span></span><br></pre></td></tr></table></figure>

<p><img src="1584367353177.png" alt="1584367353177"></p>
<p>基本上，我们已经为狗门挑战创建出模拟器。我们已创建一款应用程序，其能从摄像机中提取输入、将其转换为网络所期望的数据类型、生成输出，并将该输出转换为对用户有用的内容。</p>
<p>您能够了解如何通过正确的输出来轻松控制狗门的动力开关装置。在深度学习方面，您已掌握所需的一切！如要查看可在以上代码块中试用的其他图像<code>列表</code>，您可通过运行下方命令来找到测试图像（不用于训练的图像）。其中一些图像预计会输出错误分类。您需要不断测试这些图像直到取得满意的结果为止，然后再继续课程学习，以了解如何提高性能！</p>
<h2 id="融会贯通"><a href="#融会贯通" class="headerlink" title="融会贯通"></a>融会贯通</h2><p>我们来系统全面地理解一下该部署过程，看看它在此 Jupyter notebook 之外会是什么样。在 <a href="http://ec2-54-227-229-252.compute-1.amazonaws.com/Bamaudsn/edit/tasks/task3/task/pythondeployment.py" target="_blank" rel="noopener">pythondeployment.py</a> 的 Python 文件中，您将看到与上文相同的代码，不过此处代码已合并至同一个文件。在课程末尾的“评估”一节中，您将使用此方法，所以现在请作一些了解。将文件路径插入到此处的测试图像，以对其进行可视化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">TEST_IMAGE = <span class="string">'/dli/data/dogscats/test/1.jpg'</span></span><br><span class="line">display= caffe.io.load_image(TEST_IMAGE)</span><br><span class="line">plt.imshow(display)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>然后，运行我们的小型 python 应用程序，并按下方输入该图像。请忽略输出的大部分内容，并滚动至底部。（即使出现错误和警告也没关系。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!python pythondeployment.py $TEST_IMAGE <span class="number">2</span>&gt;/dev/null</span><br><span class="line">[[ <span class="number">0.42844081</span>  <span class="number">0.57155913</span>]]</span><br><span class="line">Output:</span><br><span class="line">Welcome dog! https://www.flickr.com/photos/aidras/<span class="number">5379402670</span></span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure>



<h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h3 id="使用部署"><a href="#使用部署" class="headerlink" title="使用部署"></a>使用部署</h3><p>滑动窗口法需要部署经过训练的图像分类器，以在应用程序中将图像的 256X256 图块分类为“狗”或“猫”，而应用程序则会每次以 256X256 大小的窗口在图像上移动。虽然这一解决方案并不完美，但却可以：</p>
<p>1) 构建一个综合运用深度学习和传统编程的典型方法，从而打造出先前无法构建的应用程序 2) 引导启发学习神经网络架构</p>
<p>在本课程第一节中，您已学习如何成功<em>训练</em>及<em>部署</em>神经网络。您了解到，传统编程不足以支持图像分类，而深度学习不仅能够实现图像分类，还能以直观方式进行呈现。</p>
<p>到目前为止，您已采用现有神经网络和开源数据集（狗和猫），并创建出一个模型，用来对与初始数据集相像及不相像的新动物进行正确分类。这相当厉害！</p>
<p>在<strong>此</strong>任务中，您将学习如何通过以下方式以利用深度学习解决<em>图像分类之外</em>的问题：</p>
<ul>
<li>将深度学习与传统计算机视觉相结合</li>
<li>修改神经网络的内部结构（实际数学运算的部分）</li>
<li>选择适合任务的神经网络</li>
</ul>
<p>并进而解决第二项深度学习挑战：</p>
<p><strong>我们能否在图像中检测并定位物体？</strong></p>
<p>首先，我们会采用与上一节相同的方式，将模型实例化。我们引入模型和数据集工作目录来利用模型架构、经过训练的权重和预处理信息（如均值图像）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#Data is often stored as "Numpy Arrays"</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#matplotlib.pyplot allows us to visualize results</span></span><br><span class="line"><span class="keyword">import</span> caffe <span class="comment">#caffe is our deep learning framework, we'll learn a lot more about this later in this task.</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">MODEL_JOB_DIR = <span class="string">'/dli/data/digits/20180301-185638-e918'</span>  <span class="comment">## Remember to set this to be the job directory for your model</span></span><br><span class="line">DATASET_JOB_DIR = <span class="string">'/dli/data/digits/20180222-165843-ada0'</span>  <span class="comment">## Remember to set this to be the job directory for your dataset</span></span><br><span class="line"></span><br><span class="line">MODEL_FILE = MODEL_JOB_DIR + <span class="string">'/deploy.prototxt'</span>                 <span class="comment"># This file contains the description of the network architecture</span></span><br><span class="line">PRETRAINED = MODEL_JOB_DIR + <span class="string">'/snapshot_iter_735.caffemodel'</span>    <span class="comment"># This file contains the *weights* that were "learned" during training</span></span><br><span class="line">MEAN_IMAGE = DATASET_JOB_DIR + <span class="string">'/mean.jpg'</span>                      <span class="comment"># This file contains the mean image of the entire dataset. Used to preprocess the data.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Tell Caffe to use the GPU so it can take advantage of parallel processing. </span></span><br><span class="line"><span class="comment"># If you have a few hours, you're welcome to change gpu to cpu and see how much time it takes to deploy models in series. </span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"><span class="comment"># Initialize the Caffe model using the model trained in DIGITS</span></span><br><span class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</span><br><span class="line">                       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</span><br><span class="line">                       raw_scale=<span class="number">255</span>,</span><br><span class="line">                       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># load the mean image from the file</span></span><br><span class="line">mean_image = caffe.io.load_image(MEAN_IMAGE)</span><br><span class="line">print(<span class="string">"Ready to predict."</span>)</span><br></pre></td></tr></table></figure>

<p>接着，我们将直接从前门监控摄像头中获取一张图像。请注意，此图像大于 256X256。我们想知道狗在此图像中位于<em>何处</em>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Choose a random image to test against</span></span><br><span class="line"><span class="comment">#RANDOM_IMAGE = str(np.random.randint(10))</span></span><br><span class="line">IMAGE_FILE = <span class="string">'/dli/tasks/task5/task/images/LouieReady.png'</span></span><br><span class="line">input_image= caffe.io.load_image(IMAGE_FILE)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="使用我们所学的函数：前向传播"><a href="#使用我们所学的函数：前向传播" class="headerlink" title="使用我们所学的函数：前向传播"></a>使用我们所学的函数：前向传播</h3><p>这就是我们的关注所在。我们来看看这个函数： <code>prediction = net.predict([grid_square])</code>。</p>
<p>与其他任一 <a href="https://www.khanacademy.org/computing/computer-programming/programming#functions" target="_blank" rel="noopener">函数</a>类似，<code>net.predict</code> 也会传递输入 <code>grid_square</code>，并返回输出 <code>预测</code>。但与其他函数不同，该函数并不遵循一组步骤，而是逐层开展矩阵数学运算，以将图像转换为概率向量。</p>
<p>运行以下单元，以从我们随机图像左上方的 256X256 <code>grid_square</code> 查看预测。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">X = <span class="number">0</span></span><br><span class="line">Y = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">grid_square = input_image[X*<span class="number">256</span>:(X+<span class="number">1</span>)*<span class="number">256</span>,Y*<span class="number">256</span>:(Y+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line"><span class="comment"># subtract the mean image (because we subtracted it while we trained the network - more on this in next lab)</span></span><br><span class="line">grid_square -= mean_image</span><br><span class="line"><span class="comment"># make prediction</span></span><br><span class="line">prediction = net.predict([grid_square])</span><br><span class="line"><span class="keyword">print</span> prediction</span><br></pre></td></tr></table></figure>

<p>这是所用网络最后一层的输出。层类型为“softmax”，其中每个单元的值越高，图像属于该类的可能性就越大。在上例中，如果向量的第二个单元高于第一个（且网络已经过训练），则该部分图像便可能包含<em>狗\</em>。由于在本例中，第一个单元<em>远</em>高于第二个，因此很显然，网络并未在左上方的 256x256 网格中检测到狗。</p>
<p>可选：<a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="noopener">探索 softmax 的数学运算。</a></p>
<p>接下来，我们将对此函数实施一些代码以对图像进行迭代，并对每个 grid_square 进行分类以创建热图。请注意，本节的课程关键在于，我们可以在此函数上构建“任何东西”，但凡所想，均可构建。</p>
<p>根据具体编程（尤其是 Python）操作的差异，您或许会从以下单元获得截然不同的信息。其核心是，这个块会把我们的输入图像分割成 256X256 大小的方块，并会在我们的狗分类器中对其逐一运行；之后此块会根据分类器所得结果创建新图像，其中没有狗时图像为蓝色，而有狗时则为红色。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the input image into a numpy array and display it</span></span><br><span class="line">input_image = caffe.io.load_image(IMAGE_FILE)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate how many 256x256 grid squares are in the image</span></span><br><span class="line">rows = input_image.shape[<span class="number">0</span>]/<span class="number">256</span></span><br><span class="line">cols = input_image.shape[<span class="number">1</span>]/<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((rows,cols))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over each grid square using the model to make a class prediction</span></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        grid_square = input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># subtract the mean image</span></span><br><span class="line">        grid_square -= mean_image</span><br><span class="line">        <span class="comment"># make prediction</span></span><br><span class="line">        prediction = net.predict([grid_square]) </span><br><span class="line">        detections[i,j] = prediction[<span class="number">0</span>].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections, interpolation=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'Total inference time: '</span> + str(end-start) + <span class="string">' seconds'</span></span><br></pre></td></tr></table></figure>

<p>同样，这是随机选择的广域测试图像的输出结果和一个数组，显示输入到模型的每个非重叠 256x256 网格的预测类。</p>
<p>在我们更好地解决问题之前，请花一分钟时间回想刚才的操作，并回答以下问题：</p>
<p><strong>用您自己的话描述一下我们刚刚如何使用图像分类器检测物体？</strong></p>
<p>本节旨在说明任何深度学习解决方案都不过是从输入到输出的映射。这一实现手段使我们能够更易理解如何构建更复杂的解决方案。例如，Alexa、Google Assistant 和 Siri 之类的语音助手必须将原始声音数据转换为文本，并将文本转换为相应的理解，最后再将相应的理解转换为预期任务，例如播放您最喜爱的歌曲。</p>
<p>其复杂性影响之广堪比任何已经或能够借助计算机科学构建的内容。请思考，在解决此类编码/问题所面临的挑战中，有哪些因素是我们未考虑到的，又该如何对其进行处理？</p>
<p>可能的答案：[单击此处](<a href="http://ec2-54-173-199-14.compute-1.amazonaws.com/33avr1Ti/notebooks/tasks/task5/task/Object" target="_blank" rel="noopener">http://ec2-54-173-199-14.compute-1.amazonaws.com/33avr1Ti/notebooks/tasks/task5/task/Object</a> detection-zh.ipynb#answer1)</p>
<h3 id="1-4-挑战性练习（可选）："><a href="#1-4-挑战性练习（可选）：" class="headerlink" title="1.4 挑战性练习（可选）："></a>1.4 挑战性练习（可选）：</h3><p>1.使网格大小保持在 256x256，修改代码以增加网格间的重叠，并获得更精细的分类地图。</p>
<p>2.修改代码以将多个网格批量传递到网络中进行预测。</p>
<p>答案：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">MODEL_JOB_NUM = <span class="string">'##FIXME##'</span>  <span class="comment">## Remember to set this to be the job number for your model</span></span><br><span class="line">DATASET_JOB_NUM = <span class="string">'##FIXME##'</span>  <span class="comment">## Remember to set this to be the job number for your dataset</span></span><br><span class="line"></span><br><span class="line">MODEL_FILE = <span class="string">'/dli/data/digits/'</span> + MODEL_JOB_NUM + <span class="string">'/deploy.prototxt'</span>                 <span class="comment"># Do not change</span></span><br><span class="line">PRETRAINED = <span class="string">'/dli/data/digits/'</span> + MODEL_JOB_NUM + <span class="string">'/snapshot_iter_735.caffemodel'</span>    <span class="comment"># Do not change</span></span><br><span class="line">MEAN_IMAGE = <span class="string">'/dli/data/digits/'</span> + DATASET_JOB_NUM + <span class="string">'/mean.jpg'</span>                      <span class="comment"># Do not change</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># load the mean image</span></span><br><span class="line">mean_image = caffe.io.load_image(MEAN_IMAGE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Choose a random image to test against</span></span><br><span class="line"><span class="comment">#RANDOM_IMAGE = str(np.random.randint(10))</span></span><br><span class="line">IMAGE_FILE = <span class="string">'/dli/data/LouieReady.png'</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># Tell Caffe to use the GPU</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"><span class="comment"># Initialize the Caffe model using the model trained in DIGITS</span></span><br><span class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</span><br><span class="line">                       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</span><br><span class="line">                       raw_scale=<span class="number">255</span>,</span><br><span class="line">                       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the input image into a numpy array and display it</span></span><br><span class="line">input_image = caffe.io.load_image(IMAGE_FILE)</span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate how many 256x256 grid squares are in the image</span></span><br><span class="line">rows = input_image.shape[<span class="number">0</span>]/<span class="number">256</span></span><br><span class="line">cols = input_image.shape[<span class="number">1</span>]/<span class="number">256</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Subtract the mean image</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>] -= mean_image</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((rows,cols))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Iterate over each grid square using the model to make a class prediction</span></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        grid_square = input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># make prediction</span></span><br><span class="line">        prediction = net.predict([grid_square])</span><br><span class="line">        detections[i,j] = prediction[<span class="number">0</span>].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'Total inference time (sliding window without overlap): '</span> + str(end-start) + <span class="string">' seconds'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the amount of overlap between grid cells</span></span><br><span class="line">OVERLAP = <span class="number">0.25</span></span><br><span class="line">grid_rows = int((rows<span class="number">-1</span>)/(<span class="number">1</span>-OVERLAP))+<span class="number">1</span></span><br><span class="line">grid_cols = int((cols<span class="number">-1</span>)/(<span class="number">1</span>-OVERLAP))+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">"Image has %d*%d blocks of 256 pixels"</span> % (rows, cols)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"With overlap=%f grid_size=%d*%d"</span> % (OVERLAP, grid_rows, grid_cols)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((grid_rows,grid_cols))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterate over each grid square using the model to make a class prediction</span></span><br><span class="line">start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,grid_rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,grid_cols):</span><br><span class="line">        start_col = int(j*<span class="number">256</span>*(<span class="number">1</span>-OVERLAP))</span><br><span class="line">        start_row = int(i*<span class="number">256</span>*(<span class="number">1</span>-OVERLAP))</span><br><span class="line">        grid_square = input_image[start_row:start_row+<span class="number">256</span>, start_col:start_col+<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># make prediction</span></span><br><span class="line">        prediction = net.predict([grid_square])</span><br><span class="line">        detections[i,j] = prediction[<span class="number">0</span>].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> (<span class="string">'Total inference time (sliding window with %f%% overlap: '</span> % (OVERLAP*<span class="number">100</span>)) + str(end-start) + <span class="string">' seconds'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># now with batched inference (one column at a time)</span></span><br><span class="line"><span class="comment"># we are not using a caffe.Classifier here so we need to do the pre-processing</span></span><br><span class="line"><span class="comment"># manually. The model was trained on random crops (256*256-&gt;227*227) so we</span></span><br><span class="line"><span class="comment"># need to do the cropping below. Similarly, we need to convert images</span></span><br><span class="line"><span class="comment"># from Numpy's Height*Width*Channel (HWC) format to Channel*Height*Width (CHW) </span></span><br><span class="line"><span class="comment"># Lastly, we need to swap channels from RGB to BGR</span></span><br><span class="line">net = caffe.Net(MODEL_FILE, PRETRAINED, caffe.TEST)</span><br><span class="line">start = time.time()</span><br><span class="line">net.blobs[<span class="string">'data'</span>].reshape(*[grid_cols, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize an empty array for the detections</span></span><br><span class="line">detections = np.zeros((rows,cols))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,rows):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        grid_square = input_image[i*<span class="number">256</span>:(i+<span class="number">1</span>)*<span class="number">256</span>,j*<span class="number">256</span>:(j+<span class="number">1</span>)*<span class="number">256</span>]</span><br><span class="line">        <span class="comment"># add to batch</span></span><br><span class="line">        grid_square = grid_square[<span class="number">14</span>:<span class="number">241</span>,<span class="number">14</span>:<span class="number">241</span>] <span class="comment"># 227*227 center crop        </span></span><br><span class="line">        image = np.copy(grid_square.transpose(<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)) <span class="comment"># transpose from HWC to CHW</span></span><br><span class="line">        image = image * <span class="number">255</span> <span class="comment"># rescale</span></span><br><span class="line">        image = image[(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>), :, :] <span class="comment"># swap channels</span></span><br><span class="line">        net.blobs[<span class="string">'data'</span>].data[j] = image</span><br><span class="line">    <span class="comment"># make prediction</span></span><br><span class="line">    output = net.forward()[net.outputs[<span class="number">-1</span>]]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,cols):</span><br><span class="line">        detections[i,j] = output[j].argmax()</span><br><span class="line">end = time.time()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Display the predicted class for each grid square</span></span><br><span class="line">plt.imshow(detections)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Display total time to perform inference</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">'Total inference time (batched inference): '</span> + str(end-start) + <span class="string">' seconds'</span></span><br></pre></td></tr></table></figure>

<p>正如当前所示，此滑动窗口法的优点在于我们可以仅使用基于局部的训练数据（可以更广泛地获取）训练检测器，且能帮助我们凭借当前的技能组合着手解决问题。</p>
<p>我们可以不断调整代码以确认自己能否继续通过蛮力解决问题（错误且缓慢），但也可学习更多有关深度学习的知识。我们来选择第二种方式。</p>
<h2 id="方法-2-–-基于已有神经网络进行重建-¶-http-ec2-54-173-199-14-compute-1-amazonaws-com-33avr1Ti-notebooks-tasks-task5-task-Object-detection-zh-ipynb-方法-2-–-基于已有神经网络进行重建"><a href="#方法-2-–-基于已有神经网络进行重建-¶-http-ec2-54-173-199-14-compute-1-amazonaws-com-33avr1Ti-notebooks-tasks-task5-task-Object-detection-zh-ipynb-方法-2-–-基于已有神经网络进行重建" class="headerlink" title="方法 2 – 基于已有神经网络进行重建[¶](http://ec2-54-173-199-14.compute-1.amazonaws.com/33avr1Ti/notebooks/tasks/task5/task/Object detection-zh.ipynb#方法-2-–-基于已有神经网络进行重建)"></a>方法 2 – 基于已有神经网络进行重建[¶](<a href="http://ec2-54-173-199-14.compute-1.amazonaws.com/33avr1Ti/notebooks/tasks/task5/task/Object" target="_blank" rel="noopener">http://ec2-54-173-199-14.compute-1.amazonaws.com/33avr1Ti/notebooks/tasks/task5/task/Object</a> detection-zh.ipynb#方法-2-–-基于已有神经网络进行重建)</h2><p>请记住，深度神经网络的构建灵感源自于人脑。本节将说明如何<em>更改</em>网络以改变其行为和性能。就其核心而言，这些网络均由数学运算组成，改变数学运算即会改变大脑。本节不会全面深入地解释各类网络可完美解决各类问题的具体<em>原因</em>，因为这是一种会随时间逐渐累积的直觉知识。相反，本节将侧重介绍您在试验期间需牢记的限制条件。我们可能会介绍一些常见的层类型，但这并非本课程的内容要点。</p>
<p>我们先来探讨一下当前的网络 AlexNet 吧。</p>
<h3 id="2-1-当前网络"><a href="#2-1-当前网络" class="headerlink" title="2.1 当前网络"></a>2.1 当前网络</h3><p>这些网络的结构均会在某类<em>框架</em>中进行说明，而本例中使用的是 Caffe 框架。<a href="https://developer.nvidia.com/deep-learning-frameworks" target="_blank" rel="noopener">框架种类数不胜数</a>，其中每种框架都能使从业者对网络进行宏观描述，而不必对 GPU 进行物理编程以执行张量数学运算。</p>
<h2 id="方法-3：DetectNet"><a href="#方法-3：DetectNet" class="headerlink" title="方法 3：DetectNet"></a>方法 3：DetectNet</h2><p>在此实验开始时，我们采用的是 AlexNet，这是一款针对极具体<em>图像分类</em>问题的卓越解决方案。我们对其构建一些 Python 代码，然后开展轻微的网络手术，以此来完成一项在利用深度学习开始<em>目标检测</em>工作之前本不可能达成的任务。</p>
<p>不过，是否存在一款专门针对<em>目标检测</em>的卓越解决方案？我们能否建立一个模型，使其直接从输入（航拍照片）映射至预想的输出（定位和检测信息）？</p>
<p>此解决方案的存在将有助我们拓广对深度学习的定义，并能帮助您深入了解可借助其解决哪些<em>其他</em>问题。</p>
<p>本课程首先讨论的是深度学习得以实现的三个要素。</p>
<p>1) 深度神经网络 2) GPU 3) 大数据</p>
<p>当我们超出图像分类的讨论范围时，以上要素仍保持不变，但网络类型、数据和 GPU 的使用会有所不同。我们将从数据谈起，因为这是我们的工作流程在 DIGITS 中的组织方式。</p>
<h3 id="数据差异"><a href="#数据差异" class="headerlink" title="数据差异"></a>数据差异</h3><p>如要构建端到端监督式深度学习工作流程，我们需要已标记的数据。到目前为止，我们已将“已标记”定义为每个图像所属类别的指标。然而，标记数据的真正目的在于**创建输入输出映射。”</p>
<p>在本例中，我们希望输入“任意”尺寸的图像，且输出结果应能表明物体在图像中的所处位置。首先，请输入图像：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input_image = caffe.io.load_image(<span class="string">'/dli/data/train/images/488156.jpg'</span>) <span class="comment">#!ls this directory to see what other images and labels you could test</span></span><br><span class="line">plt.imshow(input_image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>然后，为其加上对应标签：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat <span class="string">'/dli/data/train/labels/488156.txt'</span> <span class="comment">#"cat" has nothing to do with the animals, this displays the text</span></span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>1) 输入及其对应输出基于文件编号一一照应。 2) 所见向量由输入图像中狗的左上方和底部位置的 (x,y) 坐标构成。 3) 如果有足够的冲浪板数据，我们则可训练冲浪板检测器而非狗检测器！在本例中，我们会将数据集设置为只寻找狗。</p>
<p>将此数据集加载到 DIGITS 中。</p>
<p>从 <a href="http://ec2-54-173-199-14.compute-1.amazonaws.com/digits" target="_blank" rel="noopener">DIGITS</a> 主页面中，选择“Datasets”（数据集），然后添加新的<strong>“目标检测”数据集。</strong>请注意，这些参数看起来不同于进行分类时的参数。</p>
<p>打开“New Object Detection Dataset”（新的目标检测数据集）面板后，请使用以下图像的预处理选项（<strong>请留意前部/尾部间距</strong>）：</p>
<p>训练图像文件夹：/dli/data/train/images 训练标签文件夹：/dli/data/train/labels 验证图像文件夹：/dli/data/val/images 验证标签文件夹：/dli/data/val/labels/dog 补齐图像（宽 x 高）：640 x 640 自定义类：dontcare, dog 组名称：MS-COCO 数据集名称：coco-dog</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CUDA/" rel="tag"># CUDA</a>
              <a href="/tags/GPU/" rel="tag"># GPU</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/29/2020-02-29-MachineLearning/" rel="prev" title="Machine_Learning">
      <i class="fa fa-chevron-left"></i> Machine_Learning
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/03/09/2020-03-09-ImageProcessCV/" rel="next" title="图像处理与视频分析的笔记">
      图像处理与视频分析的笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Allocating-Memory-to-be-accessed-on-the-GPU-and-the-CPU"><span class="nav-number">1.</span> <span class="nav-text">Allocating Memory to be accessed on the GPU and the CPU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Sets-Larger-then-the-Grid"><span class="nav-number">2.</span> <span class="nav-text">Data Sets Larger then the Grid</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-Handling"><span class="nav-number">3.</span> <span class="nav-text">Error Handling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA-Error-Handling-Function"><span class="nav-number">3.1.</span> <span class="nav-text">CUDA Error Handling Function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Final-Exercise-Accelerate-Vector-Addition-Application"><span class="nav-number">3.2.</span> <span class="nav-text">Final Exercise: Accelerate Vector Addition Application</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Grids-and-Blocks-of-2-and-3-Dimensions"><span class="nav-number">4.</span> <span class="nav-text">Grids and Blocks of 2 and 3 Dimensions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Exercise-Accelerate-2D-Matrix-Multiply-Application"><span class="nav-number">4.1.</span> <span class="nav-text">Exercise: Accelerate 2D Matrix Multiply Application</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Exercise-Accelerate-A-Thermal-Conductivity-Application"><span class="nav-number">4.2.</span> <span class="nav-text">Exercise: Accelerate A Thermal Conductivity Application</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#前向传播：使用您的模型"><span class="nav-number">5.</span> <span class="nav-text">前向传播：使用您的模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成有用的输出：后处理"><span class="nav-number">6.</span> <span class="nav-text">生成有用的输出：后处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#融会贯通"><span class="nav-number">7.</span> <span class="nav-text">融会贯通</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测"><span class="nav-number"></span> <span class="nav-text">目标检测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#使用部署"><span class="nav-number">0.1.</span> <span class="nav-text">使用部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用我们所学的函数：前向传播"><span class="nav-number">0.2.</span> <span class="nav-text">使用我们所学的函数：前向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-挑战性练习（可选）："><span class="nav-number">0.3.</span> <span class="nav-text">1.4 挑战性练习（可选）：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方法-2-–-基于已有神经网络进行重建-¶-http-ec2-54-173-199-14-compute-1-amazonaws-com-33avr1Ti-notebooks-tasks-task5-task-Object-detection-zh-ipynb-方法-2-–-基于已有神经网络进行重建"><span class="nav-number">1.</span> <span class="nav-text">方法 2 – 基于已有神经网络进行重建[¶](http:&#x2F;&#x2F;ec2-54-173-199-14.compute-1.amazonaws.com&#x2F;33avr1Ti&#x2F;notebooks&#x2F;tasks&#x2F;task5&#x2F;task&#x2F;Object detection-zh.ipynb#方法-2-–-基于已有神经网络进行重建)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-当前网络"><span class="nav-number">1.1.</span> <span class="nav-text">2.1 当前网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#方法-3：DetectNet"><span class="nav-number">2.</span> <span class="nav-text">方法 3：DetectNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数据差异"><span class="nav-number">2.1.</span> <span class="nav-text">数据差异</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">acewzj</p>
  <div class="site-description" itemprop="description">acewzj</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">21</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/acewzj" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;acewzj" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wzhongjie816@gmail.com" title="E-Mail → mailto:wzhongjie816@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/acewzj" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;acewzj" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">acewzj</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
